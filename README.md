## Experimenting with Power Divergences for Language Modeling

This repository contains the code used for the paper "Experimenting with Power Divergences for Language Modeling" (https://www.aclweb.org/anthology/D19-1421/). It is based upon the setup of the ASGD weight-dropped LSTM (AWD-LSTM) models of Merity et al. (2018) (https://github.com/salesforce/awd-lstm-lm/).
The code can be run with the version 1.2.0 of Pytorch.